# Chatbot Project

Welcome to the **Chatbot Project**! This repository contains a simple AI-powered chatbot implemented using **FastAPI, CrewAI, and Ollama**. The chatbot serves as an interactive assistant, leveraging **local AI models** to process and respond to user queries.

## ğŸ“Œ Project Structure
```
AI/
 â”œâ”€â”€ Chatbot/
 â”‚   â”œâ”€â”€ chatbot.py          # The main backend API
 â”‚   â”œâ”€â”€ index.html          # The frontend UI
 â”‚   â”œâ”€â”€ requirements.txt    # List of dependencies
 â”œâ”€â”€ README.md               # Project documentation
```

## ğŸš€ Getting Started
To use or enhance this project, follow these steps:

### 1ï¸âƒ£ **Set Up Anaconda & Create a Conda Environment**
This project uses **Anaconda Navigator** to manage dependencies and environments.

#### **Install Anaconda (if not already installed)**
Download and install Anaconda from [here](https://www.anaconda.com/download/).

#### **Create a New Conda Environment**
To ensure dependencies are properly managed, create a virtual environment:
```bash
conda create --name chatbot_env python=3.12
```
Activate the environment:
```bash
conda activate chatbot_env
```

### 2ï¸âƒ£ **Install Required Dependencies**
The `requirements.txt` file contains all the necessary libraries for this project. Install them using:
```bash
pip install -r requirements.txt
```
This will install:
- **FastAPI** â€“ Framework for building APIs
- **CrewAI** â€“ AI agent framework for managing conversations
- **CrewAI Tools** â€“ Additional tools for CrewAI
- **Uvicorn** â€“ ASGI server for FastAPI
- **LiteLLM** â€“ Lightweight LLM model integration
- **Ollama** â€“ Local AI model execution

### 3ï¸âƒ£ **Run the Chatbot Backend**
Start the FastAPI server by running:
```bash
python AI/Chatbot/chatbot.py
```
By default, the API will run on `http://127.0.0.1:8000`

### 4ï¸âƒ£ **Understanding the Chatbot Architecture**
The chatbot works by using **AI agents** powered by CrewAI, with **Ollama** as the underlying LLM (local language model). Hereâ€™s how it works:
- The chatbot API receives a request from the frontend.
- CrewAI creates an **Agent** that handles user interactions.
- **Ollama (Phi-4 model)** processes the request and generates a response.
- The chatbot responds back via FastAPI.

### 5ï¸âƒ£ **Access the Chatbot Interface**
Open `index.html` in a browser or use a simple HTTP server:
```bash
python -m http.server 8080
```
Then, visit: `http://127.0.0.1:8080/index.html`

## ğŸ¯ Purpose of Key Files
- **`chatbot.py`**: Implements the FastAPI backend, initializes CrewAI agents, and integrates with Ollama.
- **`index.html`**: Frontend UI for interacting with the chatbot.
- **`requirements.txt`**: List of required libraries to ensure consistency across environments.

## ğŸ¤ Contributing
Pull requests are welcome! If youâ€™d like to enhance this project, feel free to fork the repository, make changes, and submit a PR.

## ğŸ“œ License
This project is licensed under the MIT License.

---
ğŸ“¢ **Enjoy building with AI! Feel free to customize and improve this chatbot!** ğŸš€

